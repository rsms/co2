#include "coimpl.h"
#include "hash.h"

/*
MC debugging note to self:
  autorun build.sh src/hash.* -- "./build.sh -fast && ./deps/llvm/bin/llvm-objdump \
    --disassemble out/fast/src.hash.c.o > out/fast/src.hash.c.o.asm"
*/

#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wimplicit-fallthrough"
#define XXH_INLINE_ALL
#include "xxhash.h"
#pragma GCC diagnostic pop

static u64 fastrand_state = 1;

void fastrand_seed(u64 seed) {
  fastrand_state = seed;
}

u32 fastrand() {
  #ifdef __SIZEOF_INT128__
    // wyrand (https://github.com/wangyi-fudan/wyhash)
    // clang13 -O3 -mtune=native generates ~48 bytes (11 instrs) of x86_64 code for this
    fastrand_state += 0xa0761d6478bd642f;
    __uint128_t r =
      (__uint128_t)fastrand_state * (__uint128_t)(fastrand_state ^ 0xe7037ed1a0b428db);
    #if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
      u64 hi = ((u64*)&r)[0], lo = ((u64*)&r)[1];
    #else
      u64 hi = ((u64*)&r)[1], lo = ((u64*)&r)[0];
    #endif
    return (u32)(hi ^ lo);
  #else
    // Implement xorshift64+: 2 32-bit xorshift sequences added together.
    // Shift triplet [17,7,16] was calculated as indicated in Marsaglia's
    // Xorshift paper: https://www.jstatsoft.org/article/view/v008i14/xorshift.pdf
    // This generator passes the SmallCrush suite, part of TestU01 framework:
    // http://simul.iro.umontreal.ca/testu01/tu01.html
    u32 s1 = ((u32*)&fastrand_state)[0];
    u32 s0 = ((u32*)&fastrand_state)[1];
    s1 ^= s1 << 17;
    s1 = s1 ^ s0 ^ s1>>7 ^ s0>>16;
    ((u32*)&fastrand_state)[0] = s0;
    ((u32*)&fastrand_state)[1] = s1;
    return s0 + s1;
  #endif
}

#if UINTPTR_MAX >= 0xFFFFFFFFFFFFFFFFu
  #define HASHFUN(p, size, seed) XXH3_64bits_withSeed(p, size, seed)
#else
  #define HASHFUN() (uintptr)XXH3_64bits_withSeed(p, size, (u)seed)
  // #define HASHFUN XXH32
#endif

// Note: xxhash functions are inlined; we "instantiate" only a few, a balance
// between code size and specialization.

// make sure hash_N functions using hash_mem doesn't cause inline instances
__attribute__((noinline))
uintptr hash_mem(const void* p, uintptr size, uintptr seed) {
  // TODO: condsider a smaller hash algo.
  // The code generated by xxhash for arbitrary-size hashing is quite large.
  // Go uses a custom small-ish hash algo that uses hardware instructions like AES
  // when available. See go/src/runtime/alg.go
  return HASHFUN(p, size, seed);
}

uintptr hash_2(const void* v, uintptr seed) {
  return hash_mem(v, 2, seed);
}

uintptr hash_4(const void* v, uintptr seed) {
  return HASHFUN(v, 4, seed);
}

uintptr hash_8(const void* v, uintptr seed) {
  // clang13 -O3 -mtune=native generates ~112 bytes (31 instrs) of x86_64 code for this
  return HASHFUN(v, 8, seed);
}

// floating point hash functions inspired by Golang

static const uintptr c0 =
  ((uintptr)(8-sizeof(void*))/4*2860486313u + (sizeof(void*)-4)/4*33054211828000289u);
static const uintptr c1 =
  ((uintptr)(8-sizeof(void*))/4*3267000013 + (sizeof(void*)-4)/4*23344194077549503);

uintptr hash_f32(const f32* p, uintptr h) {
  f32 f = *p;
  if (f == 0.0f)
    return c1 * (c0 ^ h); // +0, -0
  if (UNLIKELY(f != f))
    return c1 * (c0 ^ h ^ (uintptr)fastrand()); // any kind of NaN
  return hash_mem(p, 4, h);
}

uintptr hash_f64(const f64* p, uintptr h) {
  f64 f = *p;
  if (f == 0.0)
    return c1 * (c0 ^ h); // +0, -0
  if (UNLIKELY(f != f))
    return c1 * (c0 ^ h ^ (uintptr)fastrand()); // any kind of NaN
  return hash_mem(p, 8, h);
}
